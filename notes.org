* What is this thing?

It's maybe something like a wiki, only with Clojurey bits. I have a
grander vision of it being a self-modifying web app, but that's a
bigger goal than it just being a wikilike thing.

* What's the deal with the name?

> 1. Ingenious and complex in design or function; intricate.
> 2. Finely or skillfully made or employed; artistic.

Which is both something to aspire to and also a pun on the fact that
the results of my efforts are likely to be complex rather than simple.

* What are the core ideas?

That is an excellent question, that I unfortunately do not yet have an
answer to.

* What do I want it to do?

In a perfect world:

- Store data in a location of the user's choice. Default Datomic, but
  also file system, and possibly git repo.
  - Publishing changes by pushing would be cool.
- Uses GitHub-flavored Markdown, or a compatible super- or subset.
  - I sort of like the idea of metadata going in HTTP-style headers
- Allows you to use other formats
- Always has extensibility points for injecting code
- Runs code in something like CloJail, or otherwise has a model for
  only authorized users being able to add code.
- Is nice enough that we could use it for the things that Michael
  likes to use middleman for.
- Has a good story for ClojureScript/JavaScript integration, whatever
  that means.
- Data all the things - everything should be data where possible.
- Provide branching and merging of content
  - Perhaps store the content directly in git soas to leverage its
    abilities in this area. Datomic could still store metadata
  - What advantages at this point over just having a GitHub wiki?
    - Inclusion of executable code, for one
- Provide a convenient way to promote content through environments
  - This might be a feature of branching/merging
  - Might need to be able to easily promote across physical
    environments, though, if separate storages are dictated
    - That's possibly a problem to leave for later


* What do I need to look at?

** TODO Middleman
  - The syntax for integrating code
  - What features it provides
*** Notes

- Has templates for getting started
  - a la Rails generators, I think
- Has "extensions", whatever those are
  - Extensions can contribute templates
- Uses file naming conventions to separate template language from
  output format
  - Not sure what I think of that. It doesn't feel primitive.
- The main supported template language seems to be ERb.
- HAML is also supported, and I think Michael likes it better.

** TODO Flexwiki
  - The syntax for integrating code
  - How layouts were specified
** TODO Markdown
  - Especially GitHub-flavored markdown
  - What are the bits of syntax we can pervert to our own ends but
    still have something reasonable rendered?
    - E.g. can we do something like =```clojure exec= and still get
      clojure highlighting?

** TODO [[https://github.com/jgm/gitit][gitit]]
- A wiki built on top of git. Written in Haskell, interestingly.

** TODO Pandoc
- What do the extensions to Markdown offer?
- Can the tool itself be integrated in an interesting way?

** TODO ERb
*** Notes

- Is it as simple as just supporting <% %> and <%= %> ?
  - No, it's more complicated than that
- Docs [[http://www.ruby-doc.org/stdlib-2.0.0/libdoc/erb/rdoc/ERB.html][here]].
- Also has comment syntax, which seems important.
- Obviously, an escape sequence is also important. Erb uses <%% and %%>

** TODO HAML
*** Notes

- Emphasizes readability of markup
  - Partly by relying on whitespace instead of close tags
- Has a convenient way to combine running code and emitting it inside
  a tag: %strong= item.title
- Supports attributes as maps, which I find somewhat uglier, but still
  workable
- Seems strongly tied to Ruby, but then again I'm thinking of tying to
  Clojure.
- Supports shorthand for emitting ID and class via the classic # and .
  mechanism.
- Defaults to <div> element

** TODO [[http://wiki.squeak.org/swiki/][Swiki]]

- A wiki engine written in Squeak. Might be the sort of self-modifying
  thingy that I have in mind.
- Somehow related to Commanche.
** TODO JGit
Does JGit give us anything useful? For example, does it deal with CRLF
issues, or with computing SHAs? It looks like ObjectDatabase *might*
be flexible enough that we could actually implement it on top of
Datomic.

One thing I want to be sure we can do is to keep stuff like the
committer separate. That is, I don't want to be forced down a road
where I'd have to deal with commits as byte streams in the JGit
libraries, and then have to tease them back apart so they could be
stored in Datomic with the committer broken out separately.

It looks like JGit has an implementation of a Git HTTP server that we
might be able to use. I'm guessing that means we have to implement
ObjectDatabase...

GitServlet seems to be the key. It has a .setRepositoryResolver that
takes a RepositoryResolver, which is presumably how we get from names
to instances of Repostiory.

* Wiki ideas

** Git is the information model

If we adopt the git information model (trees of trees), then we can
use git tooling to modify the data. But it does mean the database has
to accommodate anything that someone might do locally. It doesn't have
to be valid input to the wiki - i.e. there might be an error when
someone tries to render it - but we have to at least agree to store it
and try to render it.

** The information is stored in a database

Not only does this give us query, but it gives us a convenient way to
use the git model while still being able to distribute access to it
across multiple machines. Reading from files on disk is a pain from
multiple machines, but reading from a database is easy. And Datomic
will let us know when something has changed, which we can use to
invalidate local caches.

Note that we don't need to store *all* the information in the
database. In particular, the byte streams that make up the content
could live elsewhere. Because they're immutable, we only need to look
at them long enough to record metadata about them. Then we can copy or
move them somewhere like S3 for other nodes to retrieve (and cache) if
they want to. We might even be able to use something like git
alternates to offload object retrieval directly onto the git client
tooling.

** Pluggable format support

There shouldn't be one format that the wiki requires, but rather an
information and/or processing model that different grammars/languages
can be parsed to.

** Metadata

Pages should be able to have metadata associated with them. Things
like "category". Metadata should be extensible (namespaced). I sort of
like the idea of having optional headers at the beginning of the file
of the form =Name.space/Name: Value= (for a topic expressed in
markup), where a blank line indicates termination of the metadata and
the beginning of content.

** Code and content are separate repositories

If the underlying storage for the wiki is the git model, and the
output of the wiki depends on both the code and the content in the
wiki, then it might help to have the code and the content be in
different repositories. That gives us a convenient way to track the
validity of the output with just two numbers: the SHAs of the commits
of the code used to generate the output was generated.

It would be possible to have more fine-grained dependency tracking.
For instance, to watch the execution of output generation to build a
dependency graph. But that gets weird because we have to do things
like figure out whether code was emitting links to all topics in a
given category. Which we could invalidate by *adding* content, which
wouldn't get picked up by a straight topic-level dependency graph.

By moving to a single version number for the entire corpus (the git
SHA of a tip ref), we have a number that encompasses the entirety of
the inputs. I.e. if output is seen as a function taking the entire
content and code bases and producing output, then if we have a number
that only changes when the code and content change, then we can
trivially cache.

At some point I had it in my head what problem splitting the code from
the content solves, but now I can't remember what it is. Especially
given that if a topic contains script (or even if it doesn't), it can
be considered code. So what's the difference?

** Content is hierarchical and links can be relative

There should be a way of organizing the content into groups, and
linking between/within groups should have a "natural" syntax. For
instance, something like =[ [ Foo ] ]= should link to a topic Foo in
the same namespace as the source document, but we should also be able
to do things like =[ [Foo/Bar] ]= and =[ [../Foo/Bar]]=.

The real question here is whether there are other parts of the
hierarchy. For instance, if I w

* Random idea parking lot

- Something akin to macro expansion - a data model for pages that has
  an extension point so that it can recursively expend into the base
  information model.
- It would be great if whatever this is were amenable to both static
  and dynamic sites.
- Designer support should be very good. What does this mean? That
  there be a way to integrate Compass/SASS? Something more?
  - It seems like it might be important to use exactly those tools if
    the support comes from the ability to control the markup, rath
- If the primitive format is something other than text, we will need
  to preserve whitespace and comments in the serialized form.
- For formats that don't support it, metadata is at the start of the
  file, as name: value pairs, with a blank line separating. Start with
  a blank line to indicate a desire for no metadata.
- Should metadata have a schema? For instance, it might be nice to say
  cardinality many or one, as a way of giving semantics to hierarchies
  of content, where a topic has metadata that's the same as a parent.
  But that raises the question: where should metadata schema be kept?
  And if it's editable by the user, then what happens if they make a
  change that invalidates content in the wiki? And again, what about
  history? If I change schema, what does it mean about values for
  those metadata types in the past?
- Maybe the model should be that whatever markup syntax we use, if its
  value is a string (or maybe a vector), then it should render
  literally. But if it's a function, then the function should be
  executed. That would allow us to save some of the work during page
  parsing, because the presence of a <% (or whatever) block could
  trigger emission of a function instead of a literal.
  - Or maybe it should be a sequence of things, where some things
    render as literals and some render as functions. Or records
    implementing some protocol or something. Actually, I like the
    protocol idea - should give us a nice information model.
  - An interesting litmus test: can we have inclusion? Like, can one
    topic include another? Could I write my docs as a wiki, where the
    doc page has something like <%(include "comments/foo")%> and the
    content for =comments/foo= gets pulled in?
- It really would be nice to support git as a backend. I'm not sure
  whether we would need to have that be git+Datomic or just git. It
  seems like it would be good to have one or the other, since
  operationally having to have both is less than awesome.
  - Question: is there a difference between content and code? And are
    both managed by the system?
  - If we do have a Datomic component, presumably it needs the same
    sort of things that git has - a tree of trees, with mutable
    pointers to places in the tree.
  - Can we separate the git aspect from the storage aspect? I.e. could
    we have a component whose job it was just to sync to/from git, but
    the local filesystem would be the store? That seems sort of messy,
    especially in the face of the need to reconcile conflicts.
  - Seems like the easiest thing is just to have a Datomic back end,
    use the git model, and later maybe allow content to live in git.
  - Especially since it doesn't look like there's any way to have a
    programmatic interface to a git repo - you have to land files on
    disk.
  - Maybe there needs to be a way to "symlink" in a namespace, which
    is a git repo with content, and the rest of the content can live
    in files or Datomic or wherever. That's a lot like FlexWiki's
    "Federations" idea.
- I think one big mistake we made with FlexWiki was in having a
  separate configuration mechanism. It should have been possible to
  edit the configuration as wiki data. Of course, that raises the
  question, if the data lives in Datomic, is the URI configuration
  data, and if so how does the application bootstrap? Or maybe the
  location of the configuration database is something that has to be
  communicated separately, like as a system property.
  - Or it could be stored on the local filesystem, and the system
    could ask you to change it if it's not present. That would give a
    pretty nice startup experience. Assuming we don't run afoul of
    filesystem permissions. The web server would have to have the
    ability to write into the configuration directory.
- What do we think of the convention in FlexWiki of having metatopics
  prefixed with an underscore?
- Goal: make a system that stores content in Datomic, using only
  Markdown, and lets you edit via the Ace editor. See how it feels.


* Prototypes
** Prototype 1 (SimpleWiki)

*** Description

A simple wiki system that stores Markdown content in Datomic and lets
you edit it.

*** URLs

- =/= - redirects to /content/home
- =/content= - this is where the topics live
- =/content/foo= - Renders topic foo
- =/edit?topic=foo= - Edits topic foo

*** Tools

- Pedestal
- [[https://github.com/chameco/Hitman][Hitman]]

*** Notes

If we assume the git model (see [[Prototype 2]]), then we can store the
existence of items in Datomic, but perhaps not the objects themselves.
We can have data *derived* from the objects (e.g. parsed metadata,
link graphs, table of contents data), that can be stored in Datomic or
not - it's derived, so it can be recomputed from the source data any
time.

**** TODO Immutability of derived data

One question this raises is how to deal with the relationship between
the source data and the derived data. This is only deterministic if
the logic doesn't change. But that implies somehow tracking the
characteristics of the code that generated it. If we keep the code in
the repository as well, then that's fine, but it does mean that we'd
have to track the version number in the derived data. And possibly
update derived data when either the source data *or* the generating
code updates. That might imply that an artifact generated from two
sources has its own identity and version history, and we'd need a way
to address it that took that into account.

A similar problem arises with conditionals. For example, if a page is
shown differently to different users based on whether or not they are
authenticated. Now not only does the output depend on the sources, but
it depends on the environment as well.

** Prototype 2 (gitomic)

*** Tasks
**** TODO Implement Repository over memory
- Just use an atom hold a map
- Point is to see what it looks like in the simplest form possible.
- Might make sense to pseudocode first
*** Description

An implementation of one of the git protocols backed by Datomic.

*** Links

- [[http://git-scm.com/book/en/Git-Internals-Transfer-Protocols][Git Transfer Protocols]]
- [[http://download.eclipse.org/jgit/docs/latest/apidocs/][JGit]] - Might provide code that can be leveraged to create packfiles
- [[https://github.com/git/git/blob/master/Documentation/technical/http-protocol.txt][The Git Protocol Documentation]]

*** Open questions

**** DONE Simple or smart transfer protocol?

Smart would be better, if we can manage it. The clients all default to
it.

**** TODO Can I store the objects elsewhere?
***** TODO If I do, do I give up some aspects in the way of query

But only over the parts that are actually stored elsewhere. And
they're immutable. Which means that there can be copies of them and it
doesn't cause trouble.

***** TODO Maybe combine it with ElasticSearch somehow?

This should be possible because of immutability. I don't know much
about ElasticSearch, but the objects should be able to be copied to
wherever it lives, and the answers almost trivially combined with the
answers obtained from the authoritative source in Datomic.

***** TODO Does using [[http://dustin.sallings.org/2008/12/30/git-alternates.html][git alternates]] help at all?

**** TODO How to represent info?

If we're going to implement a git protocol on top of what's in
Datomic, does it make sense to store it in the git way? Or to project
some internal model out via git?

I suspect we're going to find that if we really want to manage
information via git, we're going to have to conform to the git data
model completely. Which I'm not that familiar with, but is probably
roughly "trees of files". I think we could probably get away with
downloading stuff from some other information model, and maybe even
modifying it, but that arbitrary modifications to a cloned copy would
be hard to integrate in some other model.

**** TODO What is the git information model?

A commit contains metadata plus a tree, where a is tree {object |
tree}. But that's probably too simple a view.


**** TODO Should I use the codeq attributes?
On the one hand, they exist. But do they do me any good? If I'm
storing repos, rather than metadata about repos, then do I really gain
anything by reusing the schema? Plus some things seem a little weird,
like the prevalence of ref/many attributes.

The thing is, it's probably better to use them than not use them, even
if I don't expect the data to be stored in the same database, if for
no other reason than that someone smart thought about how to do it.
*** Schema
- From codeq
  - :git/type [keyword] - Type enum for git objects - one
    of :commit, :tree, :blob, :tag
  - :git/sha [string] - A git sha, should be in repo
  - :repo/commits [ref/many] - Assocate a repo with these git commits
  - :repo/uri [string] - A git repo URI
  - :commit/parents [ref/many] - Parents of a commit
  - :commit/tree [ref] - Root node of a commit
  - :commit/message [string] - A commit message
  - :commit/author [ref] - Person who authored a commit
  - :commit/authoredAt [inst] - Timestamp of authorship of commit
  - :commit/committer [ref] - Person who committed a commit
  - :commit/committedAt [inst] - Timestamp of a commit
  - :tree/nodes [ref/many] - Nodes of a git tree
  - :node/filename [ref] - filename of a tree node
  - :node/paths [ref/many] - Paths of a tree node
  - :node/object [ref] - Git object (tree/blob) in a tree node
  - :git/prior [ref] - Node containing prior value of a git object
  - :email/address [string] - An email address
  - :file/name [string] - A filename

- Others needed
  - :ref/name [string] - name of a ref like HEAD or master
  - :ref/repo [ref] - The repo this ref belongs to
  - :git/commit [ref] - A commit
  - :node/mode [???] - The mode bits for a node

Is that enough? Let's think about a simple repo:

#+begin_example
[<repo1> :repo/uri "foo/bar"]
[<HEAD1> :ref/repo <repo1>]
[<HEAD1> :git/commit <commit1>]
[<master1> :ref/repo <repo1>]
[<commit1> :commit/tree <tree1>]
[<commit1> :commit/message "Initial commit"]
[...additional <commit1> datoms]
[<commit2> :commit/parents <commit1>]
[...additional <commit2> datoms]
[<tree1> :tree/nodes #{<subtree1> <blob1> <blob2>}]
[<subtree1> :tree/nodes #{<blob3>}]
[<blob1> ???

TODO: more
#+end_example

*** Operations Needed
**** TODO hash-object
- Take a file and get the corresponding SHA for it

*** Trace of Git network protocol

If I start a local "server" with =nc -l 8888= and run =git clone
http://localhost:8888=, I get this:

#+begin_quote
GET /info/refs?service=git-upload-pack HTTP/1.1
User-Agent: git/1.7.12
Host: localhost:8888
Accept: */*
Pragma: no-cache

#+end_quote

Note the =service=git-upload-pack=, which seems to be the indicator
for the "smart" protocol. If we do

=curl -i https://github.com/candera/emacs.git/info/refs?service=git-upload-pack=:

#+begin_quote
HTTP/1.1 200 OK
Date: Sun, 08 Dec 2013 15:26:15 GMT
Server: Apache
Expires: Fri, 01 Jan 1980 00:00:00 GMT
Pragma: no-cache
Cache-Control: no-cache, max-age=0, must-revalidate
Transfer-Encoding: chunked
Content-Type: application/x-git-upload-pack-advertisement

001e# service=git-upload-pack
000000d3a0b4d7f22ebeb8558089ce798ac3c50cf99043e5 HEADmulti_ack thin-pack side-band side-band-64k ofs-delta shallow no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/1.8.5.1
003fa0b4d7f22ebeb8558089ce798ac3c50cf99043e5 refs/heads/master
0000
#+end_quote

So, that looks like a line-oriented protocol, where the first line is
the length prefix 001e (decimal 30) followed by the comment
=# service=git-upload-pack=. Which is only 25 characters long. Maybe
it includes the =0000= from the next line? No, actually, the 001e
includes the length itself, so that's just the first line. Then
there's a 0000, then a 00d3, which is the remainder of that line.

Actually, it looks like things are described in the
[[https://github.com/git/git/blob/master/Documentation/technical/pack-protocol.txt][protocol]] [[https://github.com/git/git/blob/master/Documentation/technical/http-protocol.txt][documentation]].

Let's try a trace from an empty repo:

=curl -i https://github.com/candera/test1.git/info/refs?service=git-upload-pack=

#+begin_quote
HTTP/1.1 200 OK
Date: Sun, 15 Dec 2013 21:43:06 GMT
Server: Apache
Expires: Fri, 01 Jan 1980 00:00:00 GMT
Pragma: no-cache
Cache-Control: no-cache, max-age=0, must-revalidate
Transfer-Encoding: chunked
Content-Type: application/x-git-upload-pack-advertisement

001e# service=git-upload-pack
00000000
#+end_quote

So, an empty list of refs.

What if we add a single, empty commit?

=curl -i https://github.com/candera/test1.git/info/refs?service=git-upload-pack=

#+begin_quote
HTTP/1.1 200 OK
Date: Sun, 15 Dec 2013 23:00:29 GMT
Server: Apache
Expires: Fri, 01 Jan 1980 00:00:00 GMT
Pragma: no-cache
Cache-Control: no-cache, max-age=0, must-revalidate
Transfer-Encoding: chunked
Content-Type: application/x-git-upload-pack-advertisement

001e# service=git-upload-pack
000000d349e88f45f319508612b588d9bada36a65bcccd12 HEAD multi_ack
thin-pack side-band side-band-64k ofs-delta shallow no-progress
include-tag multi_ack_detailed no-done
symref=HEAD:refs/heads/master agent=git/1.8.5.1
003f49e88f45f319508612b588d9bada36a65bcccd12 refs/heads/master
0000
#+end_quote

And the only commit is 49e88f45f319508612b588d9bada36a65bcccd12. So it
looks like the format is 00d3 for the length, then the SHA, then HEAD,
then a null and a bunch of capabilities. Then another SHA and another
ref.

What if I push one more commit on a different branch?

#+begin_src sh
  cd /tmp
  git clone git@github.com:candera/test1.git
  cd test1
#+end_src

#+RESULTS:
| Cloning  | into            | test1 |
| Checking | connectivity... | done  |

#+begin_src sh
  cd /tmp/test1
  git checkout -b new
  touch README.md
  git add .
  git commit -m "Adding README"
  git push -u origin new
#+end_src

#+RESULTS:
| #       | On  | branch  | new     |           |       |        |        |     |      |         |
| nothing | to  | commit, | working | directory | clean |        |        |     |      |         |
| Branch  | new | set     | up      | to        | track | remote | branch | new | from | origin. |

OK, now let's see what we get when we curl:

#+begin_src sh :results output
  curl -i https://github.com/candera/test1.git/info/refs?service=git-upload-pack
#+end_src

#+RESULTS:
#+begin_example
HTTP/1.1 200 OK
Date: Tue, 17 Dec 2013 05:00:05 GMT
Server: Apache
Expires: Fri, 01 Jan 1980 00:00:00 GMT
Pragma: no-cache
Cache-Control: no-cache, max-age=0, must-revalidate
Transfer-Encoding: chunked
Content-Type: application/x-git-upload-pack-advertisement

001e# service=git-upload-pack
000000d349e88f45f319508612b588d9bada36a65bcccd12 HEAD multi_ack
 thin-pack side-band side-band-64k ofs-delta shallow no-progress
 include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master
 agent=git/1.8.5.1
003f49e88f45f319508612b588d9bada36a65bcccd12 refs/heads/master
003c54d2d53541ca45c45cb2891fac746420e4b88499 refs/heads/new
0000
#+end_example

OK, so that seems good. Now, what's the next thing that happens in the
protocol? I believe that it goes something like this (captured from
interaction with a different repo):

#+begin_example
POST https://github.com:443/candera/daedal.git/git-upload-pack HTTP/1.1
User-Agent: git/1.7.12
Host: github.com
Accept-Encoding: deflate, gzip
Content-Type: application/x-git-upload-pack-request
Accept: application/x-git-upload-pack-result
Content-length: 174

006fwant 5d694187bcbd9382b167544c05efd3fdf9ed75e8 multi_ack_detailed
 no-done side-band-64k thin-pack ofs-delta
0032want 5d694187bcbd9382b167544c05efd3fdf9ed75e8
00000009done
#+end_example

I'm not sure why it lists two want lines. That seems a bit weird. But
once again it's a list of SHAs, where the first one includes
capabilities, and then a 0000, and then a terminator. Let's go read
[[https://github.com/git/git/blob/master/Documentation/technical/pack-protocol.txt][the pack protocol docs]] and [[https://github.com/git/git/blob/master/Documentation/technical/http-protocol.txt][the http protocol docs]].

This is the response:

#+begin_example
HTTP/1.1 200 OK
Date: Sun, 15 Dec 2013 17:36:39 GMT
Server: Apache
Expires: Fri, 01 Jan 1980 00:00:00 GMT
Pragma: no-cache
Cache-Control: no-cache, max-age=0, must-revalidate
X-Transfer-Encoding: chunked
Content-Type: application/x-git-upload-pack-result
Content-length: 13222

0008NAK
0021Counting objects: 31, done.
0029Compressing objects:   4% (1/22)
0085Compressing objects:   9% (2/22)
Compressing objects:  13% (3/22)
Compressing objects:  18% (4/22)
Compressing objects:0081  22% (5/22)
Compressing objects:  27% (6/22)
Compressing objects:  31% (7/22)
Compressing objects:  36% (8/22)
0029Compressing objects:  40% (9/22)
002aCompressing objects:  45% (10/22)
004fCompressing objects:  50% (11/22)
Compressing objects:  54% (12/22)
004fCompressing objects:  59% (13/22)
Compressing objects:  63% (14/22)
002aCompressing objects:  68% (15/22)
002aCompressing objects:  72% (16/22)
004fCompressing objects:  77% (17/22)
Compressing objects:  81% (18/22)
002aCompressing objects:  86% (19/22)
002aCompressing objects:  90% (20/22)
002aCompressing objects:  95% (21/22)
002aCompressing objects: 100% (22/22)
002eCompressing objects: 100% (22/22), done.
2004PACK <<begin binary crap>>
#+end_example

Capabilities are listed [[https://github.com/git/git/blob/master/Documentation/technical/protocol-capabilities.txt][here]]. Looks like the control characters are
indicating the message type, which is part of the =side-band= and
=side-band-64k= capabilities. Which is sort of neat.
